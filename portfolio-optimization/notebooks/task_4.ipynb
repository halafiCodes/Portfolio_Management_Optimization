{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0107b28",
   "metadata": {},
   "source": [
    "# Task 4 — Portfolio Optimization with MPT\n",
    "This notebook builds an optimized portfolio using the **TSLA forecast** (Task 2 model output) and **historical data** for BND and SPY. It computes expected returns, the covariance matrix, the efficient frontier, and recommends an optimal portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5e696c",
   "metadata": {},
   "source": [
    "## 1. Load Data and Define Expected Returns\n",
    "Load TSLA, BND, and SPY prices. Use the **TSLA forecast** from the Task 2 model as TSLA’s expected return, and **historical average daily returns (annualized)** for BND and SPY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d3fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "data_path = Path('..') / 'data' / 'processed' / 'financial_data_clean.csv'\n",
    "data = pd.read_csv(data_path, index_col='Date', parse_dates=True)\n",
    "\n",
    "required_cols = ['TSLA', 'BND', 'SPY']\n",
    "missing_cols = [c for c in required_cols if c not in data.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns in data: {missing_cols}\")\n",
    "\n",
    "prices = data[required_cols].dropna()\n",
    "\n",
    "# Load best-performing TSLA model from Task 2\n",
    "model_path = Path('..') / 'models' / 'arima_model_tsla.pkl'\n",
    "model_arima_res = joblib.load(model_path)\n",
    "\n",
    "# Forecast TSLA prices for ~12 months (252 business days)\n",
    "forecast_horizon = 252\n",
    "forecast_result = model_arima_res.get_forecast(steps=forecast_horizon)\n",
    "tsla_forecast = forecast_result.predicted_mean\n",
    "\n",
    "# Convert forecasted prices to forecasted daily returns\n",
    "tsla_forecast_returns = tsla_forecast.pct_change().dropna()\n",
    "tsla_expected_annual_return = (1 + tsla_forecast_returns.mean()) ** 252 - 1\n",
    "\n",
    "# Historical daily returns for BND & SPY (annualized)\n",
    "daily_returns = prices.pct_change().dropna()\n",
    "bnd_expected_annual_return = (1 + daily_returns['BND'].mean()) ** 252 - 1\n",
    "spy_expected_annual_return = (1 + daily_returns['SPY'].mean()) ** 252 - 1\n",
    "\n",
    "expected_returns = pd.Series({\n",
    "    'TSLA': tsla_expected_annual_return,\n",
    "    'BND': bnd_expected_annual_return,\n",
    "    'SPY': spy_expected_annual_return\n",
    "})\n",
    "\n",
    "expected_returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6608f8f8",
   "metadata": {},
   "source": [
    "## 2. Compute Daily Returns and Covariance Matrix\n",
    "Compute daily returns and the **annualized covariance matrix** used to estimate portfolio risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e724da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns = prices.pct_change().dropna()\n",
    "cov_matrix = daily_returns.cov() * 252  # annualized covariance\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfde1b4",
   "metadata": {},
   "source": [
    "## 3. Visualize Covariance Matrix Heatmap\n",
    "Inspect relationships between assets using a covariance heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104afa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cov_matrix, annot=True, fmt='.4f', cmap='coolwarm', square=True)\n",
    "plt.title('Annualized Covariance Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded7e4ad",
   "metadata": {},
   "source": [
    "## 4. Optimize Portfolios and Generate Efficient Frontier\n",
    "Use numerical optimization to estimate optimal portfolios and generate the efficient frontier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ee807",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = expected_returns.index.tolist()\n",
    "mu = expected_returns.values\n",
    "cov = cov_matrix.values\n",
    "rf = 0.02\n",
    "\n",
    "def portfolio_performance(weights):\n",
    "    ret = np.dot(weights, mu)\n",
    "    vol = np.sqrt(weights.T @ cov @ weights)\n",
    "    sharpe = (ret - rf) / vol if vol > 0 else np.nan\n",
    "    return ret, vol, sharpe\n",
    "\n",
    "# Constraints and bounds\n",
    "n_assets = len(assets)\n",
    "bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "constraints = ({'type': 'eq', 'fun': lambda w: np.sum(w) - 1},)\n",
    "\n",
    "# Minimum volatility portfolio\n",
    "def portfolio_volatility(weights):\n",
    "    return portfolio_performance(weights)[1]\n",
    "\n",
    "init_w = np.array([1 / n_assets] * n_assets)\n",
    "min_vol = minimize(portfolio_volatility, init_w, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "min_vol_w = min_vol.x\n",
    "\n",
    "# Maximum Sharpe ratio portfolio\n",
    "def negative_sharpe(weights):\n",
    "    return -portfolio_performance(weights)[2]\n",
    "\n",
    "max_sharpe = minimize(negative_sharpe, init_w, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "max_sharpe_w = max_sharpe.x\n",
    "\n",
    "# Monte Carlo simulation for efficient frontier\n",
    "n_portfolios = 10000\n",
    "all_weights = np.zeros((n_portfolios, n_assets))\n",
    "ret_arr = np.zeros(n_portfolios)\n",
    "vol_arr = np.zeros(n_portfolios)\n",
    "sharpe_arr = np.zeros(n_portfolios)\n",
    "\n",
    "for i in range(n_portfolios):\n",
    "    weights = np.random.random(n_assets)\n",
    "    weights /= np.sum(weights)\n",
    "    all_weights[i, :] = weights\n",
    "    r, v, s = portfolio_performance(weights)\n",
    "    ret_arr[i] = r\n",
    "    vol_arr[i] = v\n",
    "    sharpe_arr[i] = s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c10ec",
   "metadata": {},
   "source": [
    "## 5. Identify Maximum Sharpe and Minimum Volatility Portfolios\n",
    "Compute portfolio metrics for the tangency (maximum Sharpe) and minimum volatility portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e007744",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vol_ret, min_vol_vol, min_vol_sharpe = portfolio_performance(min_vol_w)\n",
    "max_sharpe_ret, max_sharpe_vol, max_sharpe_sharpe = portfolio_performance(max_sharpe_w)\n",
    "\n",
    "min_vol_port = pd.Series(min_vol_w, index=assets, name='Min Vol Weights')\n",
    "max_sharpe_port = pd.Series(max_sharpe_w, index=assets, name='Max Sharpe Weights')\n",
    "\n",
    "min_vol_port, max_sharpe_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c163a1ab",
   "metadata": {},
   "source": [
    "## 6. Plot Efficient Frontier with Key Portfolios Marked\n",
    "Plot the efficient frontier (risk vs. return) and mark the max Sharpe and minimum volatility portfolios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ded136",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(vol_arr, ret_arr, c=sharpe_arr, cmap='viridis', s=10, alpha=0.5)\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "\n",
    "# Mark key portfolios\n",
    "plt.scatter(min_vol_vol, min_vol_ret, color='red', s=120, marker='X', label='Min Volatility')\n",
    "plt.scatter(max_sharpe_vol, max_sharpe_ret, color='orange', s=120, marker='*', label='Max Sharpe')\n",
    "\n",
    "plt.title('Efficient Frontier (TSLA, BND, SPY)')\n",
    "plt.xlabel('Portfolio Volatility (Std Dev)')\n",
    "plt.ylabel('Expected Annual Return')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a7f20",
   "metadata": {},
   "source": [
    "## 7. Summarize Recommended Portfolio Weights and Metrics\n",
    "Select the recommended portfolio and report weights, expected return, volatility, and Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35011b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose recommended portfolio (max Sharpe by default)\n",
    "recommended = 'Max Sharpe'\n",
    "rec_w = max_sharpe_w\n",
    "rec_ret, rec_vol, rec_sharpe = max_sharpe_ret, max_sharpe_vol, max_sharpe_sharpe\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Weight': rec_w\n",
    "}, index=assets)\n",
    "\n",
    "metrics = pd.Series({\n",
    "    'Expected Annual Return': rec_ret,\n",
    "    'Expected Volatility': rec_vol,\n",
    "    'Sharpe Ratio': rec_sharpe\n",
    "})\n",
    "\n",
    "summary, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8803be",
   "metadata": {},
   "source": [
    "## 8. Portfolio Selection Justification\n",
    "The recommended portfolio is the **Maximum Sharpe Ratio (tangency) portfolio** because it provides the strongest risk‑adjusted return based on the TSLA forecast and the historical behavior of BND and SPY. This choice balances expected performance with volatility, which is especially important when forecast uncertainty grows over a 12‑month horizon. If a lower‑risk profile is preferred, the minimum volatility portfolio is the conservative alternative, but it typically sacrifices expected return. Given the objective to optimize return for a given level of risk, the max‑Sharpe allocation is the most defensible recommendation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
